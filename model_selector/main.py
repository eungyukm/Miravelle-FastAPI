import os
from fastapi import FastAPI
import redis
import clip
import torch
from PIL import Image
import os
import torchvision.transforms as transforms
from torchvision.models import resnet50, ResNet50_Weights
import torch.nn as nn
import numpy as np

app = FastAPI()
nima_base = resnet50(weights=ResNet50_Weights.DEFAULT)

# Redis ì—°ê²°
redis_client = redis.Redis(host='localhost', port=6379, decode_responses=True)

# CLIP ëª¨ë¸ ë¡œë“œ
device = "cuda" if torch.cuda.is_available() else "cpu"
clip_model, preprocess = clip.load("ViT-B/32", device=device)

# NIMA ëª¨ë¸ ì •ì˜ (ë¯¸ì  í’ˆì§ˆ í‰ê°€)
class NIMA(nn.Module):
    def __init__(self, base_model):
        super(NIMA, self).__init__()
        self.base_model = base_model
        self.fc = nn.Linear(1000, 10)  # 10ê°œì˜ ì ìˆ˜ ì˜ˆì¸¡

    def forward(self, x):
        x = self.base_model(x)
        x = self.fc(x)
        return torch.softmax(x, dim=1)

# NIMA ëª¨ë¸ ë¡œë“œ
nima_base = resnet50(pretrained=True)
nima_model = NIMA(nima_base).to(device)
nima_model.eval()

# 3D ëª¨ë¸ í´ë”
image_folder = "generated_3d_models"

# ìœ ì‚¬ë„ í‰ê°€ í•¨ìˆ˜
def get_clip_score(image_path, input_text):
    text_features = clip_model.encode_text(clip.tokenize(input_text).to(device))
    image = preprocess(Image.open(image_path)).unsqueeze(0).to(device)
    image_features = clip_model.encode_image(image)
    similarity = torch.cosine_similarity(text_features, image_features)
    return similarity.item() * 100  # 100ì  ê¸°ì¤€ ë³€í™˜

# í’ˆì§ˆ í‰ê°€ í•¨ìˆ˜ (NIMA)
def get_nima_score(image_path):
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
    ])
    
    image = Image.open(image_path)
    
    # RGBA (4ì±„ë„) â†’ RGB (3ì±„ë„) ë³€í™˜
    if image.mode == "RGBA":
        image = image.convert("RGB")

    image = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        scores = nima_model(image).cpu().numpy()[0]
    
    mean_score = np.dot(scores, np.arange(1, 11))  # í‰ê·  ì ìˆ˜ ê³„ì‚°
    return mean_score * 10  # 100ì  ê¸°ì¤€ ë³€í™˜

# ìµœì  ëª¨ë¸ ì„ íƒ
def get_best_model(image_files, input_text):
    best_model = None
    best_final_score = -1

    for image_path in image_files:
        # ì´ë¯¸ì§€ íŒŒì¼ë§Œ ì²˜ë¦¬ ('.DS_Store' ê°™ì€ íŒŒì¼ ì œì™¸)
        if not image_path.lower().endswith((".png", ".jpg", ".jpeg")):
            print(f"ë¬´ì‹œëœ íŒŒì¼: {image_path}")  # ë””ë²„ê¹… ë¡œê·¸
            continue

        clip_score = get_clip_score(image_path, input_text)
        nima_score = get_nima_score(image_path)

        # í•„í„° ì¡°ê±´
        if nima_score < 70:
            continue  

        final_score = (nima_score * 0.8) + (clip_score * 0.2)

        if final_score > best_final_score:
            best_final_score = final_score
            best_model = image_path

    return best_model, best_final_score

# API ì—”ë“œí¬ì¸íŠ¸ (Redis ì ìš©)
@app.get("/select-best-model/")
async def select_best_model(keyword: str):
    print(f"ğŸ”¥ ìš”ì²­ë°›ì€ í‚¤ì›Œë“œ: {keyword}")  # í‚¤ì›Œë“œ í™•ì¸

    # ì´ë¯¸ì§€ íŒŒì¼ ëª©ë¡ ë¶ˆëŸ¬ì˜¤ê¸°
    image_files = [os.path.join(image_folder, img) for img in os.listdir(image_folder)]
    image_files = [img for img in image_files if img.lower().endswith((".png", ".jpg", ".jpeg"))]

    print(f"ğŸ“‚ ì°¾ì€ ì´ë¯¸ì§€ íŒŒì¼ ëª©ë¡: {image_files}")  # ì´ë¯¸ì§€ íŒŒì¼ì´ ì œëŒ€ë¡œ ë¡œë“œë˜ëŠ”ì§€ í™•ì¸

    best_model, best_score = get_best_model(image_files, keyword)

    if best_model:
        print(f"ìµœì  ëª¨ë¸ ì„ íƒ: {best_model} (ì ìˆ˜: {best_score})")  # ìµœì¢… ì„ íƒëœ ëª¨ë¸
        return {"best_model": best_model, "score": best_score}
    else:
        print("ì ì ˆí•œ ëª¨ë¸ì„ ì°¾ì§€ ëª»í•¨")  # ëª¨ë“  ëª¨ë¸ì´ í•„í„°ë§ë˜ì—ˆëŠ”ì§€ í™•ì¸
        return {"message": "No suitable model found"}


# ì„œë²„ ì‹¤í–‰: uvicorn main:app --reload
""""
http://127.0.0.1:8000/select-best-model/?keyword=cartoon-style+elf+mage
ì—¬ê¸°ë¡œ ë“¤ì–´ê°€ë©´ generated_3d_models í´ë”ì— ìˆëŠ” ì´ë¯¸ì§€ ì¤‘ì— ì œì¼ ê´œì°®ì€ ëª¨ë¸ì´ ë‚˜ì™€ìš©"
"""